# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eiXalLKh2XUDbcbHGeEoa6c-YFo5Khgo

**ğŸ“ Project: Chance of Admission Prediction**

ğŸ¯** Objective**
To build a machine learning model that predicts the probability of a student getting admitted to a university based on academic and profile features like GRE, TOEFL, CGPA, etc.

**ğŸ”— Data Source**
Dataset: Admission Chance CSV (YBI Foundation) [link text](https://github.com/ybifoundation/Dataset/raw/main/Admission%20Chance.csv)

**ğŸ“„ Dataset Overview **
This dataset is designed to help predict a studentâ€™s likelihood of being accepted into a graduate program based on various academic and profile-related attributes. Each record in the dataset represents an individual applicant and includes the following features:

GRE Score â€“ Graduate Record Examination score, a standardized test often required for graduate admissions.

TOEFL Score â€“ Test of English as a Foreign Language score, assessing English language proficiency.

University Rating â€“ A numerical indicator of the universityâ€™s quality or prestige (typically rated from 1 to 5).

SOP â€“ Strength of the applicantâ€™s Statement of Purpose, rated on a scale.

LOR â€“ Quality of Letters of Recommendation, rated similarly.

CGPA â€“ Cumulative Grade Point Average, measuring overall academic performance.

Research â€“ A binary value (0 or 1) indicating whether the applicant has prior research experience.

Chance of Admit â€“ The target variable representing the estimated probability of admission, ranging between 0 and 1.

This dataset is often used in machine learning tasks related to regression and prediction modeling in educational analytics.

**ğŸ“š Import Libraries**
"""

# importing the libraries required

import pandas as pd     # it handles and anlayzes structured data
import numpy as np      # it is used for numerical operations
import matplotlib.pyplot as plt   # used to visualize the data
import seaborn as sns            # more advanced visualization

from sklearn.model_selection import train_test_split   # it helps in splittting the data into training and test sets
from sklearn.linear_model import LinearRegression      # it is a linear regression algorithm
from sklearn.metrics import mean_squared_error, r2_score    # it evaluates model performance

"""**ğŸ“¥ Import Data**"""

url = "https://github.com/ybifoundation/Dataset/raw/main/Admission%20Chance.csv"
df = pd.read_csv(url)

"""**ğŸ“Š Describe Data**"""

# Clean column names
df.columns = df.columns.str.strip()

# Drop unnamed column if it exists
df = df.loc[:, ~df.columns.str.contains('^Unnamed')]

# View first few rows
df.head()

# Basic info
df.info()

# Summary statistics
df.describe()

"""**ğŸ“ˆ Data Visualization**"""

# Correlation heatmap
plt.figure(figsize=(10, 6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""**ğŸ§¹ Data Preprocessing**"""

# Check each column to see how many missing (null) values it has
df.isnull().sum()

"""**ğŸ¯ Define Target Variable (y) and Feature Variables (X)**"""

# Clean column names again just in case
df.columns = df.columns.str.strip()

X = df.drop('Chance of Admit', axis=1)
y = df['Chance of Admit']

"""**ğŸ”€ Train Test Split**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""**ğŸ¤– Modeling**"""

# Create an instance of the Linear Regression model
model = LinearRegression()

# Train the model using the training data
model.fit(X_train, y_train)

"""**ğŸ“ Model Evaluation**"""

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model
r2 = r2_score(y_test, y_pred)      # Measures how well the model fits
mse = mean_squared_error(y_test, y_pred)  # Shows average prediction error

# Print results
print(f"RÂ² Score: {r2:.4f}")
print(f"MSE: {mse:.4f}")

# Plot actual vs predicted values to see how well the model did
plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.xlabel("Actual Chance of Admit")
plt.ylabel("Predicted Chance of Admit")
plt.title("Actual vs Predicted")
plt.plot([0, 1], [0, 1], 'r--')  # Reference line for perfect predictions
plt.show()

"""**ğŸ”® Prediction**"""

# Predict on a sample student profile
sample = pd.DataFrame({
    'Serial No': [0],  # Add a placeholder for Serial No as it was in the training data
    'GRE Score': [325],
    'TOEFL Score': [112],
    'University Rating': [4],
    'SOP': [4.5],
    'LOR': [4],
    'CGPA': [9.1],
    'Research': [1]
})

predicted_chance = model.predict(sample)
print(f"Predicted Chance of Admission: {predicted_chance[0]:.2f}")

"""**ğŸ“˜ Explanation **
In this project, we used a Linear Regression model to predict a student's chance of admission by looking at key factors like their academic scores and research background.

The results show that features such as CGPA, GRE, and TOEFL scores have a significant impact on the likelihood of getting admitted. These variables are closely linked to the admission chances, meaning they play an important role in the modelâ€™s predictions.

The RÂ² Score helps us understand how well the model captures the relationship between these features and the admission probability. A higher RÂ² value means the model does a good job of explaining the variations in the data, giving us confidence in its predictions.
"""